{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af590d00",
   "metadata": {},
   "source": [
    "### **[Autoint]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f18c7d",
   "metadata": {},
   "source": [
    "- 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bceb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\MODULABS\\recommender\\DAY5\\.venv\\lib\\site-packages\\sklearn\\utils\\fixes.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, MaxPooling2D, Conv2D, Dropout, Lambda, Dense, Flatten, Activation, Input, Embedding, BatchNormalization\n",
    "from tensorflow.keras.initializers import glorot_normal, Zeros, TruncatedNormal\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87636fd",
   "metadata": {},
   "source": [
    "- Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73803af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesEmbedding(Layer):  \n",
    "    '''\n",
    "    임베딩 레이어입니다. \n",
    "    - 만약 피처(feature) 3개가 각각 10개, 20개, 30개의 고유값을 가진다면 feature_dims는 [10, 20, 30] 형태를 띄게 됩니다.\n",
    "    - 전체 임베딩을 해야 할 개수는 10+20+30 = 60이므로 '60 x 임베딩_차원_크기'의 행렬이 생성되게 됩니다.\n",
    "    '''\n",
    "    def __init__(self, field_dims, embed_dim, **kwargs):\n",
    "        super(FeaturesEmbedding, self).__init__(**kwargs)\n",
    "        self.total_dim = sum(field_dims)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int32)\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.total_dim, output_dim=self.embed_dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # 임베딩을 빌드하고 초기화\n",
    "        self.embedding.build(input_shape)\n",
    "        self.embedding.set_weights([tf.keras.initializers.GlorotUniform()(shape=self.embedding.weights[0].shape)])\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.cast(x, tf.int32)\n",
    "\n",
    "        # 들어온 입력의 임베딩 호출\n",
    "        x = x + tf.constant(self.offsets, dtype=tf.int32)\n",
    "        \n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca596fea",
   "metadata": {},
   "source": [
    "- Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12601a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(Layer):  \n",
    "    '''\n",
    "    DNN 레이어입니다.\n",
    "    - Tensorflow Keras에서는 Dense 레이어를 쌓아올린 구조입니다.\n",
    "    - 필요에 따라 배치 정규화도 사용할 수 있습니다.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_units, activation='relu', l2_reg=0, dropout_rate=0, use_bn=False, init_std=0.0001, output_layer=True):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_bn = use_bn\n",
    "        hidden_units = [input_dim] + list(hidden_units)\n",
    "        if output_layer:\n",
    "            hidden_units += [1]\n",
    "        # Dense layer\n",
    "        self.linears = [Dense(units, activation=None, kernel_initializer=tf.random_normal_initializer(stddev=init_std),\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(l2_reg)) for units in hidden_units[1:]]\n",
    "        # 활성화 함수 세팅\n",
    "        self.activation = tf.keras.layers.Activation(activation)\n",
    "        # 필요시 배치정규화 진행\n",
    "        if self.use_bn:\n",
    "            self.bn = [BatchNormalization() for _ in hidden_units[1:]]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = inputs\n",
    "        for i in range(len(self.linears)):\n",
    "            # input data가 들어오면 layer를 돌며 벡터 값 호출\n",
    "            x = self.linears[i](x)\n",
    "            if self.use_bn:\n",
    "                x = self.bn[i](x, training=training)\n",
    "            # 각 layer마다 나온 벡터 값에 활성화 함수와 dropout을 적용시켜 비선형성 구조와 과적합을 방지\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x, training=training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11d93a",
   "metadata": {},
   "source": [
    "- Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60023aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer):  \n",
    "    '''\n",
    "    멀티 헤드 셀프 어텐션 레이어입니다.\n",
    "    - 위에 작성한 수식과 같이 동작됩니다.\n",
    "    - 필요에 따라 잔차 연결(residual connection)도 진행합니다.\n",
    "    '''\n",
    "    def __init__(self, att_embedding_size=8, head_num=2, use_res=True, scaling=False, seed=1024, **kwargs):\n",
    "        if head_num <= 0:\n",
    "            raise ValueError('head_num must be a int > 0')\n",
    "        self.att_embedding_size = att_embedding_size\n",
    "        self.head_num = head_num\n",
    "        self.use_res = use_res\n",
    "        self.seed = seed\n",
    "        self.scaling = scaling\n",
    "        super(MultiHeadSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 3:\n",
    "            raise ValueError(\n",
    "                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (len(input_shape)))\n",
    "        embedding_size = int(input_shape[-1])\n",
    "        # Matrix for Query \n",
    "        self.W_Query = self.add_weight(name='query', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                       dtype=tf.float32,\n",
    "                                       initializer=TruncatedNormal(seed=self.seed))\n",
    "        # Matrix for Key \n",
    "        self.W_key = self.add_weight(name='key', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                     dtype=tf.float32,\n",
    "                                     initializer=TruncatedNormal(seed=self.seed + 1))\n",
    "        # Matrix for Value \n",
    "        self.W_Value = self.add_weight(name='value', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                       dtype=tf.float32,\n",
    "                                       initializer=TruncatedNormal(seed=self.seed + 2))\n",
    "        # 필요시 잔차 연결\n",
    "        if self.use_res:\n",
    "            self.W_Res = self.add_weight(name='res', shape=[embedding_size, self.att_embedding_size * self.head_num],\n",
    "                                         dtype=tf.float32,\n",
    "                                         initializer=TruncatedNormal(seed=self.seed))\n",
    "\n",
    "        super(MultiHeadSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if K.ndim(inputs) != 3:\n",
    "            raise ValueError(\"Unexpected inputs dimensions %d, expect to be 3 dimensions\" % (K.ndim(inputs)))\n",
    "        \n",
    "        # 입력이 들어오면 쿼리, 키, 값(value)에 매칭되어 각각의 값을 호출\n",
    "        querys = tf.tensordot(inputs, self.W_Query, axes=(-1, 0))  \n",
    "        keys = tf.tensordot(inputs, self.W_key, axes=(-1, 0))\n",
    "        values = tf.tensordot(inputs, self.W_Value, axes=(-1, 0))\n",
    "\n",
    "        # 헤드 개수에 따라 데이터를 분리\n",
    "        querys = tf.stack(tf.split(querys, self.head_num, axis=2))\n",
    "        keys = tf.stack(tf.split(keys, self.head_num, axis=2))\n",
    "        values = tf.stack(tf.split(values, self.head_num, axis=2))\n",
    "        \n",
    "        # 쿼리, 키 내적. \n",
    "        inner_product = tf.matmul(querys, keys, transpose_b=True)\n",
    "        if self.scaling:\n",
    "            inner_product /= self.att_embedding_size ** 0.5\n",
    "        self.normalized_att_scores =  tf.nn.softmax(inner_product)\n",
    "        \n",
    "        # 쿼리와 키에서 나온 어텐션 값을 값(value)과 행렬곱. \n",
    "        result = tf.matmul(self.normalized_att_scores, values)\n",
    "        \n",
    "        # multi head concat\n",
    "        result = tf.concat(tf.split(result, self.head_num, ), axis=-1)\n",
    "        result = tf.squeeze(result, axis=0) \n",
    "\n",
    "        if self.use_res:\n",
    "            result += tf.tensordot(inputs, self.W_Res, axes=(-1, 0))\n",
    "        result = tf.nn.relu(result)\n",
    "        \n",
    "        # 결과 값 리턴\n",
    "\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "\n",
    "        return (None, input_shape[1], self.att_embedding_size * self.head_num)\n",
    "\n",
    "    def get_config(self, ):\n",
    "        config = {'att_embedding_size': self.att_embedding_size, 'head_num': self.head_num, 'use_res': self.use_res,'seed': self.seed}\n",
    "        base_config = super(MultiHeadSelfAttention, self).get_config()\n",
    "        base_config.update(config)\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637f70f",
   "metadata": {},
   "source": [
    "- AutoInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6f0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoInt(Layer): \n",
    "    '''\n",
    "     AutoInt 본체입니다. 앞서서 정의한 layer를 가져와서 계산을 수행합니다.\n",
    "    '''\n",
    "    def __init__(self, field_dims, embedding_size, att_layer_num=3, att_head_num=2, att_res=True, \n",
    "                 l2_reg_dnn=0, l2_reg_embedding=1e-5, dnn_use_bn=False, dnn_dropout=0.4, init_std=0.0001):\n",
    "        super(AutoInt, self).__init__()\n",
    "\n",
    "        # 임베딩 레이어 정의. \n",
    "        self.embedding = FeaturesEmbedding(field_dims, embedding_size)\n",
    "        self.num_fields = len(field_dims)\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # 마지막 출력 레이어 정의.\n",
    "        self.final_layer = Dense(1, use_bias=False, kernel_initializer=tf.random_normal_initializer(stddev=init_std))\n",
    "\n",
    "        # 멀티 레이어 퍼셉트론 레이어 정의.\n",
    "        self.int_layers = [MultiHeadSelfAttention(att_embedding_size=embedding_size, head_num=att_head_num, use_res=att_res) for _ in range(att_layer_num)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        # input 데이터에 해당되는 embedding 값을 호출.\n",
    "        att_input = self.embedding(inputs)\n",
    "\n",
    "        # 멀티 헤드 셀프 어텐션 레이어에서 상호작용 수행.\n",
    "        for layer in self.int_layers:\n",
    "            att_input = layer(att_input)\n",
    "\n",
    "        att_output = Flatten()(att_input)\n",
    "\n",
    "        # 최종 출력. \n",
    "        att_output = self.final_layer(att_output)\n",
    "\n",
    "        # sigmoid 출력.\n",
    "        y_pred = tf.nn.sigmoid(att_output)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef0913",
   "metadata": {},
   "source": [
    "- 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20370f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수는 아래의 링크에서 가져왔습니다.\n",
    "# https://www.programcreek.com/python/?code=MaurizioFD%2FRecSys2019_DeepLearning_Evaluation%2FRecSys2019_DeepLearning_Evaluation-master%2FConferences%2FKDD%2FMCRec_our_interface%2FMCRecRecommenderWrapper.py\n",
    "\n",
    "def get_DCG(ranklist, y_true):\n",
    "    dcg = 0.0\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item in y_true:\n",
    "            dcg += 1.0 / math.log(i + 2)\n",
    "    return  dcg\n",
    "\n",
    "def get_IDCG(ranklist, y_true):\n",
    "    idcg = 0.0\n",
    "    i = 0\n",
    "    for item in y_true:\n",
    "        if item in ranklist:\n",
    "            idcg += 1.0 / math.log(i + 2)\n",
    "            i += 1\n",
    "    return idcg\n",
    "\n",
    "def get_NDCG(ranklist, y_true):\n",
    "    '''NDCG 평가 지표'''\n",
    "    ranklist = np.array(ranklist).astype(int)\n",
    "    y_true = np.array(y_true).astype(int)\n",
    "    dcg = get_DCG(ranklist, y_true)\n",
    "    idcg = get_IDCG(y_true, y_true)\n",
    "    if idcg == 0:\n",
    "        return 0\n",
    "    return round( (dcg / idcg), 5)\n",
    "\n",
    "def get_hit_rate(ranklist, y_true):\n",
    "    '''hitrate 평가 지표'''\n",
    "    c = 0\n",
    "    for y in y_true:\n",
    "        if y in ranklist:\n",
    "            c += 1\n",
    "    return round( c / len(y_true), 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f19247",
   "metadata": {},
   "source": [
    "- 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7eca34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_df):\n",
    "    '''모델 테스트'''\n",
    "    user_pred_info = defaultdict(list)\n",
    "    total_rows = len(test_df)\n",
    "    for i in range(0, total_rows, batch_size):\n",
    "        features = test_df.iloc[i:i + batch_size, :-1].values\n",
    "        y_pred = model.predict(features, verbose=False)\n",
    "        for feature, p in zip(features, y_pred):\n",
    "            u_i = feature[:2]\n",
    "            user_pred_info[int(u_i[0])].append((int(u_i[1]), float(p)))\n",
    "    return user_pred_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece7602",
   "metadata": {},
   "source": [
    "### **[Autoint 학습 데이터 세팅]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a677c",
   "metadata": {},
   "source": [
    "- 데이터 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36aea198",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\user\\Desktop\\MODULABS\\recommender\\DAY5\\autoint\\data\\ml-1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83af97f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_decade</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>rating_year</th>\n",
       "      <th>rating_month</th>\n",
       "      <th>rating_decade</th>\n",
       "      <th>genre1</th>\n",
       "      <th>genre2</th>\n",
       "      <th>genre3</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>1970s</td>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>1990s</td>\n",
       "      <td>1996</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>1960s</td>\n",
       "      <td>1964</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Romance</td>\n",
       "      <td>no</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>2000s</td>\n",
       "      <td>2000</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Drama</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>1990s</td>\n",
       "      <td>1998</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2000s</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id movie_id movie_decade movie_year rating_year rating_month  \\\n",
       "0       1     1193        1970s       1975        2001            1   \n",
       "1       1      661        1990s       1996        2001            1   \n",
       "2       1      914        1960s       1964        2001            1   \n",
       "3       1     3408        2000s       2000        2001            1   \n",
       "4       1     2355        1990s       1998        2001            1   \n",
       "\n",
       "  rating_decade     genre1      genre2   genre3 gender age occupation    zip  \\\n",
       "0         2000s      Drama          no       no      F   1         10  48067   \n",
       "1         2000s  Animation  Children's  Musical      F   1         10  48067   \n",
       "2         2000s    Musical     Romance       no      F   1         10  48067   \n",
       "3         2000s      Drama          no       no      F   1         10  48067   \n",
       "4         2000s  Animation  Children's   Comedy      F   1         10  48067   \n",
       "\n",
       "  label  \n",
       "0     1  \n",
       "1     0  \n",
       "2     0  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_rcmm = pd.read_csv(f\"{data_path}/movielens_rcmm_rating.csv\", dtype=str)\n",
    "print(movielens_rcmm.shape)\n",
    "movielens_rcmm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e426d",
   "metadata": {},
   "source": [
    "- 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1982a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 제외 각 칼럼의 고유값들을 0부터 n까지 매핑.\n",
    "label_encoders = {col: LabelEncoder() for col in movielens_rcmm.columns[:-1]} \n",
    "\n",
    "for col, le in label_encoders.items():\n",
    "    movielens_rcmm[col] = le.fit_transform(movielens_rcmm[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "debd4fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_decade</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>rating_year</th>\n",
       "      <th>rating_month</th>\n",
       "      <th>rating_decade</th>\n",
       "      <th>genre1</th>\n",
       "      <th>genre2</th>\n",
       "      <th>genre3</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3374</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3615</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2503</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1374</td>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  movie_decade  movie_year  rating_year  rating_month  \\\n",
       "0        0       189             6          55            1             0   \n",
       "1        0      3374             8          76            1             0   \n",
       "2        0      3615             5          44            1             0   \n",
       "3        0      2503             9          80            1             0   \n",
       "4        0      1374             8          78            1             0   \n",
       "\n",
       "   rating_decade  genre1  genre2  genre3  gender  age  occupation   zip label  \n",
       "0              0       7      17      15       0    0           2  1588     1  \n",
       "1              0       2       2       8       0    0           2  1588     0  \n",
       "2              0      11      12      15       0    0           2  1588     0  \n",
       "3              0       7      17      15       0    0           2  1588     1  \n",
       "4              0       2       2       2       0    0           2  1588     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens_rcmm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27ae20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000209 entries, 0 to 1000208\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   user_id        1000209 non-null  int32 \n",
      " 1   movie_id       1000209 non-null  int32 \n",
      " 2   movie_decade   1000209 non-null  int32 \n",
      " 3   movie_year     1000209 non-null  int32 \n",
      " 4   rating_year    1000209 non-null  int32 \n",
      " 5   rating_month   1000209 non-null  int32 \n",
      " 6   rating_decade  1000209 non-null  int32 \n",
      " 7   genre1         1000209 non-null  int32 \n",
      " 8   genre2         1000209 non-null  int32 \n",
      " 9   genre3         1000209 non-null  int32 \n",
      " 10  gender         1000209 non-null  int32 \n",
      " 11  age            1000209 non-null  int32 \n",
      " 12  occupation     1000209 non-null  int32 \n",
      " 13  zip            1000209 non-null  int32 \n",
      " 14  label          1000209 non-null  object\n",
      "dtypes: int32(14), object(1)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "movielens_rcmm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf5b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens_rcmm['label'] = movielens_rcmm['label'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd859d6",
   "metadata": {},
   "source": [
    "- train / test split (8:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed91bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(movielens_rcmm, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50bca8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 800167 entries, 416292 to 121958\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   user_id        800167 non-null  int32  \n",
      " 1   movie_id       800167 non-null  int32  \n",
      " 2   movie_decade   800167 non-null  int32  \n",
      " 3   movie_year     800167 non-null  int32  \n",
      " 4   rating_year    800167 non-null  int32  \n",
      " 5   rating_month   800167 non-null  int32  \n",
      " 6   rating_decade  800167 non-null  int32  \n",
      " 7   genre1         800167 non-null  int32  \n",
      " 8   genre2         800167 non-null  int32  \n",
      " 9   genre3         800167 non-null  int32  \n",
      " 10  gender         800167 non-null  int32  \n",
      " 11  age            800167 non-null  int32  \n",
      " 12  occupation     800167 non-null  int32  \n",
      " 13  zip            800167 non-null  int32  \n",
      " 14  label          800167 non-null  float32\n",
      "dtypes: float32(1), int32(14)\n",
      "memory usage: 51.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bbfc43",
   "metadata": {},
   "source": [
    "- embedding 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c40206e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6040, 3706,   10,   81,    4,   12,    1,   18,   18,   16,    2,\n",
       "          7,   21, 3439])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_i_feature = ['user_id', 'movie_id']\n",
    "meta_features = ['movie_decade', 'movie_year', 'rating_year', 'rating_month', 'rating_decade', 'genre1','genre2', 'genre3', 'gender', 'age', 'occupation', 'zip']\n",
    "label = 'label'\n",
    "field_dims = np.max(movielens_rcmm[u_i_feature + meta_features].astype(np.int32).values, axis=0) + 1    # 필드의 각 고유 개수를 정의\n",
    "field_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a06c49",
   "metadata": {},
   "source": [
    "### **[Autoint 학습 환경 및 모델 세팅]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196246d",
   "metadata": {},
   "source": [
    "- epochs, learning rate, dropout, batch, embedding dim 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349c3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "learning_rate= 0.0001\n",
    "dropout= 0.4\n",
    "batch_size = 2048\n",
    "embed_dim= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fe2a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoIntModel(Model):\n",
    "    def __init__(self, field_dims, embedding_size, att_layer_num=3, att_head_num=2\n",
    "                 , att_res=True, l2_reg_dnn=0, l2_reg_embedding=1e-5, dnn_use_bn=False\n",
    "                 , dnn_dropout=0, init_std=0.0001):\n",
    "        super(AutoIntModel, self).__init__()\n",
    "        self.autoInt_layer = AutoInt(field_dims, embedding_size, att_layer_num=att_layer_num, att_head_num=att_head_num, \n",
    "                                     att_res=att_res, l2_reg_dnn=l2_reg_dnn, dnn_dropout=dnn_dropout, init_std=init_std\n",
    "                                    )\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        return self.autoInt_layer(inputs, training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5656908",
   "metadata": {},
   "source": [
    "- 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e3a580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoInt_model = AutoIntModel(field_dims, embed_dim, att_layer_num=3, att_head_num=2, att_res=True,\n",
    "                             l2_reg_dnn=0, l2_reg_embedding=1e-5, dnn_use_bn=False\n",
    "                             , dnn_dropout=dropout, init_std=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73acc01b",
   "metadata": {},
   "source": [
    "- Optimizer, Loss function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1993dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_fn = BinaryCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233650b",
   "metadata": {},
   "source": [
    "- compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9aa269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoInt_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c65df",
   "metadata": {},
   "source": [
    "### **[훈련 및 평가]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e20bbd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "352/352 [==============================] - 25s 68ms/step - loss: 0.6738 - binary_crossentropy: 0.6738 - val_loss: 0.6321 - val_binary_crossentropy: 0.6321\n",
      "Epoch 2/5\n",
      "352/352 [==============================] - 24s 70ms/step - loss: 0.6055 - binary_crossentropy: 0.6055 - val_loss: 0.5960 - val_binary_crossentropy: 0.5960\n",
      "Epoch 3/5\n",
      "352/352 [==============================] - 24s 69ms/step - loss: 0.5842 - binary_crossentropy: 0.5842 - val_loss: 0.5772 - val_binary_crossentropy: 0.5772\n",
      "Epoch 4/5\n",
      "352/352 [==============================] - 24s 69ms/step - loss: 0.5493 - binary_crossentropy: 0.5493 - val_loss: 0.5487 - val_binary_crossentropy: 0.5487\n",
      "Epoch 5/5\n",
      "352/352 [==============================] - 23s 65ms/step - loss: 0.5365 - binary_crossentropy: 0.5365 - val_loss: 0.5447 - val_binary_crossentropy: 0.5447\n"
     ]
    }
   ],
   "source": [
    "history = autoInt_model.fit(train_df[u_i_feature + meta_features], train_df[label], epochs=epochs, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a631a214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6035/6035 [00:00<00:00, 134109.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# 사용자에게 예측된 정보를 저장하는 딕셔너리 \n",
    "user_pred_info = {}\n",
    "\n",
    "# top10개\n",
    "top = 10\n",
    "\n",
    "# 테스트 값 호출\n",
    "mymodel_user_pred_info = test_model(autoInt_model, test_df)\n",
    "\n",
    "# 예측 데이터 중 가장 높은 top 10만 호출. \n",
    "for user, data_info in tqdm(mymodel_user_pred_info.items(), total=len(mymodel_user_pred_info), position=0, leave=True):\n",
    "    ranklist = sorted(data_info, key=lambda s : s[1], reverse=True)[:top]\n",
    "    ranklist = list(dict.fromkeys([r[0] for r in ranklist]))\n",
    "    user_pred_info[str(user)] = ranklist\n",
    "\n",
    "# 원본 테스트 데이터에서 label이 1인 사용자 별 영화 정보를 호출\n",
    "test_data = test_df[test_df['label']==1].groupby('user_id')['movie_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7b3c363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5994/5994 [00:00<00:00, 18789.95it/s]\n",
      "100%|██████████| 5994/5994 [00:00<00:00, 48656.76it/s]\n"
     ]
    }
   ],
   "source": [
    "mymodel_ndcg_result = {}\n",
    "mymodel_hitrate_result = {}\n",
    "\n",
    "# 모델 예측값과 원본 테스트 데이터를 비교. 어느정도 성능이 나왔는지 NDCG와 Hitrate를 비교.\n",
    "\n",
    "# NDCG\n",
    "for user, data_info in tqdm(test_data.items(), total=len(test_data), position=0, leave=True):\n",
    "    mymodel_pred = user_pred_info.get(str(user))\n",
    "\n",
    "    testset = list(set(np.array(data_info).astype(int)))\n",
    "    mymodel_pred = mymodel_pred[:top]\n",
    "\n",
    "    # NDCG 값 구하기\n",
    "    user_ndcg = get_NDCG(mymodel_pred, testset)\n",
    "\n",
    "    mymodel_ndcg_result[user] = user_ndcg\n",
    "\n",
    "# Hitrate\n",
    "for user, data_info in tqdm(test_data.items(), total=len(test_data), position=0, leave=True):\n",
    "    mymodel_pred = user_pred_info.get(str(user))\n",
    "\n",
    "    testset = list(set(np.array(data_info).astype(int)))\n",
    "    mymodel_pred = mymodel_pred[:top]\n",
    "\n",
    "    # hitrate 값 구하기\n",
    "    user_hitrate = get_hit_rate(mymodel_pred, testset)\n",
    "\n",
    "    # 사용자 hitrate 결과 저장\n",
    "    mymodel_hitrate_result[user] = user_hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5f017cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mymodel ndcg :  0.66233\n",
      " mymodel hitrate :  0.6328\n"
     ]
    }
   ],
   "source": [
    "print(\" mymodel ndcg : \", round(np.mean(list(mymodel_ndcg_result.values())), 5))\n",
    "print(\" mymodel hitrate : \", round(np.mean(list(mymodel_hitrate_result.values())), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee107f",
   "metadata": {},
   "source": [
    "- 학습 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0950b255",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './autoint/field_dims.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./autoint/field_dims.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MODULABS\\recommender\\DAY5\\.venv\\lib\\site-packages\\numpy\\lib\\npyio.py:524\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    523\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 524\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    527\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './autoint/field_dims.npy'"
     ]
    }
   ],
   "source": [
    "np.save('./autoint/field_dims.npy', field_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54323361",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoInt_model.save_weights('./autoint/model/autoInt_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec98b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./autoint/label_encoders.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "# 모델 객체를 pickled binary file 형태로 저장\n",
    "joblib.dump(label_encoders, './autoint/label_encoders.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoint-rec-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
